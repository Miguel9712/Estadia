
# OCR Model

This OCR Model is built upon the existing blip-image-captioning-large model, originally developed and released by Salesforce AI Research and made publicly available on Hugging Face.

In this revised version, the model has been specifically adapted and optimized to improve its performance in OCR (Optical Character Recognition) tasks, with the goal of making it more effective for image-to-text applications.

All usage of this model and its derivatives is conducted in accordance with the Fair Use guidelines, as outlined by Hugging Face and the Salesforce AI Research team.


## Features

- Enhanced OCR Capabilities – This model has been fine-tuned to more accurately detect, read, and interpret text within images, significantly improving performance on image-to-text tasks.

- Multilingual Text Understanding – Trained to recognize and comprehend text in most languages, allowing for robust OCR performance in a wide range of linguistic contexts.

- Image-Based Question Answering – Beyond basic text extraction, the model can respond to contextual questions about image content. For example:
Prompt: "What is the man in the photo wearing on his head?"
Response: "The man in the photo is wearing a party hat."

- Trained on Publicly Available Datasets – The training process leveraged a diverse selection of publicly accessible datasets, enabling the model to handle a variety of image types and text styles, from printed documents to natural scene images.
## Authors

Original Model: blip-image-captioning-large
Developed by Salesforce AI Research, publicly released on Hugging Face.

Modified OCR Version: Adaptation and fine-tuning for enhanced OCR capabilities by Miguel Ángel Sánchez Piña.

Datasets: Training and fine-tuning leveraged publicly available datasets for OCR and image understanding tasks.

## Acknowledgements

Special thanks to the Hugging Face community and Salesforce AI Research for their open-source contributions, my teachers and friends which made this work possible.